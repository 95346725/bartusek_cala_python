{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit account\n",
    "#username:IES_Python\n",
    "#email:95346725@fsv.cuni.cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install praw\n",
    "#!{sys.executable} -m pip install pandas-datareader\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Yahoo_Extractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def getData(self, acro):\n",
    "        link = 'https://finance.yahoo.com/quote/' + acro + '/history?p=' + acro\n",
    "        r = requests.get(link)\n",
    "        r.encoding = 'utf-8-sig'\n",
    "        self.soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        lst = []\n",
    "        stocksDF = pd.DataFrame({'Date':pd.Series([], dtype='str'),\n",
    "                               acro:pd.Series([], dtype='str')})\n",
    "        for tr in self.soup.findAll('tr', {'class':'BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)'}):\n",
    "            Date = tr.contents[0].text\n",
    "            try:\n",
    "                Volume = tr.contents[6].text.replace(\",\",\"\")\n",
    "            except IndexError:\n",
    "                Volume = 'NA'\n",
    "            stocks_row = pd.DataFrame({'Date':pd.Series([Date], dtype='str'),\n",
    "                                     acro:pd.Series([Volume], dtype='str')})\n",
    "            stocksDF = stocksDF.append(stocks_row)\n",
    "        return stocksDF\n",
    "    \n",
    "    def joinData(self, acro):\n",
    "        finalDF = pd.DataFrame({'Date':pd.Series([], dtype='str')})\n",
    "        for a in acro:\n",
    "            start = time.time()\n",
    "            stocksDF = self.getData(a)\n",
    "            #finalDF = pd.concat([finalDF, stocksDF], axis = 1, join = 'outer', copy = False)\n",
    "            finalDF = pd.merge(finalDF, stocksDF, how = 'outer', on = 'Date', copy = False)\n",
    "            end = time.time()\n",
    "            print('Ellapsed time for stock', a)\n",
    "            print(end-start)\n",
    "        finalDF = finalDF.drop_duplicates(subset = 'Date') #removing duplicate entries  \n",
    "        return finalDF\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acro = ['MMM', 'ABT', 'ABBV', 'ABMD', 'AAPL','AMZN', 'BRK-B'] #several acronyms for test\n",
    "tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "acro = tickers[0]['Symbol'].tolist()             #creating a list of tickers\n",
    "acro = [a.replace('.', '-') for a in acro]    #converting the wikipedia ticker notation into Yahoo Finance ticker notation\n",
    "\n",
    "acro250 = acro[:251]\n",
    "acro500 = acro[252:504]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index     800\n",
       "Date     6900\n",
       "MMM      3200\n",
       "ABT      3200\n",
       "ABBV     3200\n",
       "         ... \n",
       "XYL      3200\n",
       "YUM      3200\n",
       "ZBRA     3200\n",
       "ZBH      3200\n",
       "ZION     3200\n",
       "Length: 505, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Yahoo_Extractor()\n",
    "DF250 = Y.joinData(acro250)\n",
    "DF500 = Y.joinData(acro500)\n",
    "finalDF = pd.merge(DF250, DF500, how = 'outer', on = 'Date', sort = True, copy = False)\n",
    "\n",
    "#Converting the columns to numeric for better memory allocation\n",
    "finalDF.iloc[:,1:] = finalDF.iloc[:,1:].apply(pd.to_numeric, downcast = \"unsigned\")\n",
    "finalDF.memory_usage(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "stringEpoch = today.strftime(\"%d_%m_%y\")\n",
    "s = ''\n",
    "nameVars = [\"C:\\\\Users\\\\hso20\\\\Python\\\\Project\\\\YahooData\\\\\",stringEpoch,\".csv\"]\n",
    "finalDF.to_csv(path_or_buf=s.join(nameVars),sep = ';', index=True, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
