{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reddit account\n",
    "#username:IES_Python\n",
    "#email:95346725@fsv.cuni.cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install praw\n",
    "#!{sys.executable} -m pip install pandas-datareader\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Yahoo_Extractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def getData(self, acro):\n",
    "        link = 'https://finance.yahoo.com/quote/' + acro + '/history?p=' + acro\n",
    "        r = requests.get(link)\n",
    "        r.encoding = 'utf-8-sig'\n",
    "        self.soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        lst = []\n",
    "        stocksDF = pd.DataFrame({'Date':pd.Series([], dtype='str'),\n",
    "                               acro:pd.Series([], dtype='str')})\n",
    "        for tr in self.soup.findAll('tr', {'class':'BdT Bdc($seperatorColor) Ta(end) Fz(s) Whs(nw)'}):\n",
    "            Date = tr.contents[0].text\n",
    "            try:\n",
    "                Volume = tr.contents[6].text.replace(\",\",\"\")\n",
    "            except IndexError:\n",
    "                Volume = 'NA'\n",
    "            stocks_row = pd.DataFrame({'Date':pd.Series([Date], dtype='str'),\n",
    "                                     acro:pd.Series([Volume], dtype='str')})\n",
    "            stocksDF = stocksDF.append(stocks_row)\n",
    "        return stocksDF\n",
    "    \n",
    "    def joinData(self, acro):\n",
    "        finalDF = pd.DataFrame({'Date':pd.Series([], dtype='str')})\n",
    "        for a in acro:\n",
    "            stocksDF = self.getData(a)\n",
    "            finalDF = finalDF.merge(stocksDF, how = 'outer', on = 'Date')\n",
    "        finalDF = finalDF.drop_duplicates(subset = 'Date') #removing duplicate entries   \n",
    "        return finalDF\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6294474601745605\n"
     ]
    }
   ],
   "source": [
    "Y = Yahoo_Extractor()\n",
    "\n",
    "data = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "acro = data[0]\n",
    "acro = acro['Symbol'].tolist()\n",
    "#acro = ['MMM', 'ABT', 'ABBV', 'ABMD'] #several acronyms for test\n",
    "\n",
    "start = time.time()\n",
    "finalDF = Y.joinData(acro) #the actual procedure\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "stringEpoch = today.strftime(\"%d_%m_%y\")\n",
    "s = ''\n",
    "nameVars = [\"C:\\\\Users\\\\hso20\\\\Python\\\\Project\\\\YahooData\\\\\",stringEpoch,\".csv\"]\n",
    "finalDF.to_csv(path_or_buf=s.join(nameVars),sep = ';', index=True, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
